{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a029ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imagebind_dataloader import ImageText_DataLoader, VideoText_DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from config import EPOCHS, IMAGE_TRANSFORM, VIDEO_TRANSFORM, DEVICE\n",
    "from torch.utils.data import DataLoader\n",
    "from model import ImageBindModel, ModalityType\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0116cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ds = ImageText_DataLoader(image_paths = \"Data/Image_Data\", transform = IMAGE_TRANSFORM)\n",
    "image_dl = DataLoader(image_ds, batch_size=3, shuffle=True)\n",
    "\n",
    "video_ds = VideoText_DataLoader(video_paths = \"Data/Video_Data\", transform = VIDEO_TRANSFORM)\n",
    "video_dl = DataLoader(video_ds, batch_size=3, shuffle=True)\n",
    "\n",
    "model = ImageBindModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "962ef014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from info_nce import InfoNCE, info_nce\n",
    "\n",
    "loss_fn = InfoNCE()\n",
    "batch_size, embedding_size = 32, 128\n",
    "query = torch.randn(batch_size, embedding_size)\n",
    "positive_key = torch.randn(batch_size, embedding_size)\n",
    "output = loss_fn(query, positive_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a25375",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == False:\n",
    "        print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8916690",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"{name}: {param.grad.abs().mean()}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00acbc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            if param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            else:\n",
    "                nn.init.uniform_(param, -0.01, 0.01)\n",
    "        elif 'bias' in name:\n",
    "            nn.init.constant_(param, 0.0)\n",
    "    return model\n",
    "\n",
    "model = initialize_model_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: grad={None if param.grad is None else param.grad.abs().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "420fd0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageBindModel(out_embed_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0fdedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import normalize, cross_entropy\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "def contrastive_loss(x, y, temperature=0.07):\n",
    "    \"\"\"\n",
    "    InfoNCE-style contrastive loss between x and y.\n",
    "    \"\"\"\n",
    "    logits = (x @ y.T) / temperature\n",
    "    labels = torch.arange(x.size(0)).to(x.device)\n",
    "    loss_i2t = cross_entropy(logits, labels)\n",
    "    loss_t2i = cross_entropy(logits.T, labels)\n",
    "    return (loss_i2t + loss_t2i) / 2\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-3, weight_decay=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    step = 0\n",
    "\n",
    "    pbar = tqdm(image_dl, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for image, text in pbar:\n",
    "        # Move data to device\n",
    "        image = image.to(DEVICE)\n",
    "        text = text.to(DEVICE)\n",
    "\n",
    "        # Forward pass\n",
    "        inputs = {\"vision\": image, \"text\": text}\n",
    "        embeddings = model(inputs)\n",
    "\n",
    "        # Normalize embeddings\n",
    "        img_emb = normalize(embeddings[\"vision\"], dim=-1)\n",
    "        txt_emb = normalize(embeddings[\"text\"], dim=-1)\n",
    "\n",
    "        # Compute contrastive loss\n",
    "        loss = contrastive_loss(img_emb, txt_emb)\n",
    "        print(loss)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        total_loss += loss.item()\n",
    "        step += 1\n",
    "        pbar.set_postfix(loss=total_loss / step)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Avg Loss = {total_loss / step:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8940cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modality_preprocessors.vision.cls_tokens: grad mean 0.000000\n",
      "modality_preprocessors.vision.rgbt_stem.proj.1.weight: grad mean 0.000001\n",
      "modality_preprocessors.vision.pos_embed_helper.pos_embed: grad mean 0.000000\n",
      "modality_preprocessors.text.pos_embed: grad mean 0.000002\n",
      "modality_preprocessors.text.token_embedding.weight: grad mean 0.000000\n",
      "modality_trunks.vision.pre_transformer_layer.0.weight: grad mean 0.000010\n",
      "modality_trunks.vision.pre_transformer_layer.0.bias: grad mean 0.000050\n",
      "modality_trunks.vision.blocks.0.attn.in_proj_weight: grad mean 0.000011\n",
      "modality_trunks.vision.blocks.0.attn.in_proj_bias: grad mean 0.002267\n",
      "modality_trunks.vision.blocks.0.attn.out_proj.weight: grad mean 0.000025\n",
      "modality_trunks.vision.blocks.0.attn.out_proj.bias: grad mean 0.006823\n",
      "modality_trunks.vision.blocks.0.norm1.weight: grad mean 0.000010\n",
      "modality_trunks.vision.blocks.0.norm1.bias: grad mean 0.000058\n",
      "modality_trunks.vision.blocks.0.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.0.mlp.fc1.bias: grad mean 0.000015\n",
      "modality_trunks.vision.blocks.0.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.0.mlp.fc2.bias: grad mean 0.000041\n",
      "modality_trunks.vision.blocks.0.norm2.weight: grad mean 0.000012\n",
      "modality_trunks.vision.blocks.0.norm2.bias: grad mean 0.000019\n",
      "modality_trunks.vision.blocks.1.norm1.weight: grad mean 0.000013\n",
      "modality_trunks.vision.blocks.1.norm1.bias: grad mean 0.000020\n",
      "modality_trunks.vision.blocks.1.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.1.mlp.fc1.bias: grad mean 0.000016\n",
      "modality_trunks.vision.blocks.1.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.1.mlp.fc2.bias: grad mean 0.000044\n",
      "modality_trunks.vision.blocks.1.norm2.weight: grad mean 0.000014\n",
      "modality_trunks.vision.blocks.1.norm2.bias: grad mean 0.000019\n",
      "modality_trunks.vision.blocks.2.norm1.weight: grad mean 0.000017\n",
      "modality_trunks.vision.blocks.2.norm1.bias: grad mean 0.000023\n",
      "modality_trunks.vision.blocks.2.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.2.mlp.fc1.bias: grad mean 0.000017\n",
      "modality_trunks.vision.blocks.2.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.2.mlp.fc2.bias: grad mean 0.000046\n",
      "modality_trunks.vision.blocks.2.norm2.weight: grad mean 0.000016\n",
      "modality_trunks.vision.blocks.2.norm2.bias: grad mean 0.000021\n",
      "modality_trunks.vision.blocks.3.norm1.weight: grad mean 0.000018\n",
      "modality_trunks.vision.blocks.3.norm1.bias: grad mean 0.000025\n",
      "modality_trunks.vision.blocks.3.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.3.mlp.fc1.bias: grad mean 0.000021\n",
      "modality_trunks.vision.blocks.3.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.3.mlp.fc2.bias: grad mean 0.000058\n",
      "modality_trunks.vision.blocks.3.norm2.weight: grad mean 0.000021\n",
      "modality_trunks.vision.blocks.3.norm2.bias: grad mean 0.000027\n",
      "modality_trunks.vision.blocks.4.norm1.weight: grad mean 0.000024\n",
      "modality_trunks.vision.blocks.4.norm1.bias: grad mean 0.000033\n",
      "modality_trunks.vision.blocks.4.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.4.mlp.fc1.bias: grad mean 0.000031\n",
      "modality_trunks.vision.blocks.4.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.4.mlp.fc2.bias: grad mean 0.000085\n",
      "modality_trunks.vision.blocks.4.norm2.weight: grad mean 0.000031\n",
      "modality_trunks.vision.blocks.4.norm2.bias: grad mean 0.000039\n",
      "modality_trunks.vision.blocks.5.norm1.weight: grad mean 0.000033\n",
      "modality_trunks.vision.blocks.5.norm1.bias: grad mean 0.000046\n",
      "modality_trunks.vision.blocks.5.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.5.mlp.fc1.bias: grad mean 0.000037\n",
      "modality_trunks.vision.blocks.5.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.5.mlp.fc2.bias: grad mean 0.000102\n",
      "modality_trunks.vision.blocks.5.norm2.weight: grad mean 0.000036\n",
      "modality_trunks.vision.blocks.5.norm2.bias: grad mean 0.000047\n",
      "modality_trunks.vision.blocks.6.norm1.weight: grad mean 0.000040\n",
      "modality_trunks.vision.blocks.6.norm1.bias: grad mean 0.000055\n",
      "modality_trunks.vision.blocks.6.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.6.mlp.fc1.bias: grad mean 0.000053\n",
      "modality_trunks.vision.blocks.6.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.6.mlp.fc2.bias: grad mean 0.000143\n",
      "modality_trunks.vision.blocks.6.norm2.weight: grad mean 0.000053\n",
      "modality_trunks.vision.blocks.6.norm2.bias: grad mean 0.000066\n",
      "modality_trunks.vision.blocks.7.norm1.weight: grad mean 0.000056\n",
      "modality_trunks.vision.blocks.7.norm1.bias: grad mean 0.000076\n",
      "modality_trunks.vision.blocks.7.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.7.mlp.fc1.bias: grad mean 0.000069\n",
      "modality_trunks.vision.blocks.7.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.7.mlp.fc2.bias: grad mean 0.000188\n",
      "modality_trunks.vision.blocks.7.norm2.weight: grad mean 0.000065\n",
      "modality_trunks.vision.blocks.7.norm2.bias: grad mean 0.000084\n",
      "modality_trunks.vision.blocks.8.norm1.weight: grad mean 0.000075\n",
      "modality_trunks.vision.blocks.8.norm1.bias: grad mean 0.000104\n",
      "modality_trunks.vision.blocks.8.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.8.mlp.fc1.bias: grad mean 0.000083\n",
      "modality_trunks.vision.blocks.8.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.8.mlp.fc2.bias: grad mean 0.000224\n",
      "modality_trunks.vision.blocks.8.norm2.weight: grad mean 0.000081\n",
      "modality_trunks.vision.blocks.8.norm2.bias: grad mean 0.000104\n",
      "modality_trunks.vision.blocks.9.norm1.weight: grad mean 0.000089\n",
      "modality_trunks.vision.blocks.9.norm1.bias: grad mean 0.000119\n",
      "modality_trunks.vision.blocks.9.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.9.mlp.fc1.bias: grad mean 0.000099\n",
      "modality_trunks.vision.blocks.9.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.9.mlp.fc2.bias: grad mean 0.000265\n",
      "modality_trunks.vision.blocks.9.norm2.weight: grad mean 0.000100\n",
      "modality_trunks.vision.blocks.9.norm2.bias: grad mean 0.000126\n",
      "modality_trunks.vision.blocks.10.norm1.weight: grad mean 0.000106\n",
      "modality_trunks.vision.blocks.10.norm1.bias: grad mean 0.000145\n",
      "modality_trunks.vision.blocks.10.mlp.fc1.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.10.mlp.fc1.bias: grad mean 0.000102\n",
      "modality_trunks.vision.blocks.10.mlp.fc2.weight: grad mean 0.000000\n",
      "modality_trunks.vision.blocks.10.mlp.fc2.bias: grad mean 0.000279\n",
      "modality_trunks.vision.blocks.10.norm2.weight: grad mean 0.000102\n",
      "modality_trunks.vision.blocks.10.norm2.bias: grad mean 0.000126\n",
      "modality_trunks.vision.blocks.11.norm1.weight: grad mean 0.000114\n",
      "modality_trunks.vision.blocks.11.norm1.bias: grad mean 0.000151\n",
      "modality_trunks.vision.blocks.11.mlp.fc1.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.11.mlp.fc1.bias: grad mean 0.000129\n",
      "modality_trunks.vision.blocks.11.mlp.fc2.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.11.mlp.fc2.bias: grad mean 0.000357\n",
      "modality_trunks.vision.blocks.11.norm2.weight: grad mean 0.000123\n",
      "modality_trunks.vision.blocks.11.norm2.bias: grad mean 0.000154\n",
      "modality_trunks.vision.blocks.12.norm1.weight: grad mean 0.000142\n",
      "modality_trunks.vision.blocks.12.norm1.bias: grad mean 0.000192\n",
      "modality_trunks.vision.blocks.12.mlp.fc1.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.12.mlp.fc1.bias: grad mean 0.000169\n",
      "modality_trunks.vision.blocks.12.mlp.fc2.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.12.mlp.fc2.bias: grad mean 0.000471\n",
      "modality_trunks.vision.blocks.12.norm2.weight: grad mean 0.000161\n",
      "modality_trunks.vision.blocks.12.norm2.bias: grad mean 0.000216\n",
      "modality_trunks.vision.blocks.13.norm1.weight: grad mean 0.000185\n",
      "modality_trunks.vision.blocks.13.norm1.bias: grad mean 0.000252\n",
      "modality_trunks.vision.blocks.13.mlp.fc1.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.13.mlp.fc1.bias: grad mean 0.000202\n",
      "modality_trunks.vision.blocks.13.mlp.fc2.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.13.mlp.fc2.bias: grad mean 0.000552\n",
      "modality_trunks.vision.blocks.13.norm2.weight: grad mean 0.000196\n",
      "modality_trunks.vision.blocks.13.norm2.bias: grad mean 0.000254\n",
      "modality_trunks.vision.blocks.14.norm1.weight: grad mean 0.000213\n",
      "modality_trunks.vision.blocks.14.norm1.bias: grad mean 0.000293\n",
      "modality_trunks.vision.blocks.14.mlp.fc1.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.14.mlp.fc1.bias: grad mean 0.000240\n",
      "modality_trunks.vision.blocks.14.mlp.fc2.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.14.mlp.fc2.bias: grad mean 0.000646\n",
      "modality_trunks.vision.blocks.14.norm2.weight: grad mean 0.000243\n",
      "modality_trunks.vision.blocks.14.norm2.bias: grad mean 0.000315\n",
      "modality_trunks.vision.blocks.15.norm1.weight: grad mean 0.000238\n",
      "modality_trunks.vision.blocks.15.norm1.bias: grad mean 0.000329\n",
      "modality_trunks.vision.blocks.15.mlp.fc1.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.15.mlp.fc1.bias: grad mean 0.000306\n",
      "modality_trunks.vision.blocks.15.mlp.fc2.weight: grad mean 0.000001\n",
      "modality_trunks.vision.blocks.15.mlp.fc2.bias: grad mean 0.000852\n",
      "modality_trunks.vision.blocks.15.norm2.weight: grad mean 0.000311\n",
      "modality_trunks.vision.blocks.15.norm2.bias: grad mean 0.000383\n",
      "modality_trunks.vision.blocks.16.norm1.weight: grad mean 0.000317\n",
      "modality_trunks.vision.blocks.16.norm1.bias: grad mean 0.000440\n",
      "modality_trunks.vision.blocks.16.mlp.fc1.weight: grad mean 0.000002\n",
      "modality_trunks.vision.blocks.16.mlp.fc1.bias: grad mean 0.000404\n",
      "modality_trunks.vision.blocks.16.mlp.fc2.weight: grad mean 0.000002\n",
      "modality_trunks.vision.blocks.16.mlp.fc2.bias: grad mean 0.001158\n",
      "modality_trunks.vision.blocks.16.norm2.weight: grad mean 0.000380\n",
      "modality_trunks.vision.blocks.16.norm2.bias: grad mean 0.000493\n",
      "modality_trunks.vision.blocks.17.norm1.weight: grad mean 0.000478\n",
      "modality_trunks.vision.blocks.17.norm1.bias: grad mean 0.000649\n",
      "modality_trunks.vision.blocks.17.mlp.fc1.weight: grad mean 0.000002\n",
      "modality_trunks.vision.blocks.17.mlp.fc1.bias: grad mean 0.000519\n",
      "modality_trunks.vision.blocks.17.mlp.fc2.weight: grad mean 0.000002\n",
      "modality_trunks.vision.blocks.17.mlp.fc2.bias: grad mean 0.001402\n",
      "modality_trunks.vision.blocks.17.norm2.weight: grad mean 0.000533\n",
      "modality_trunks.vision.blocks.17.norm2.bias: grad mean 0.000674\n",
      "modality_trunks.vision.blocks.18.norm1.weight: grad mean 0.000568\n",
      "modality_trunks.vision.blocks.18.norm1.bias: grad mean 0.000772\n",
      "modality_trunks.vision.blocks.18.mlp.fc1.weight: grad mean 0.000002\n",
      "modality_trunks.vision.blocks.18.mlp.fc1.bias: grad mean 0.000634\n",
      "modality_trunks.vision.blocks.18.mlp.fc2.weight: grad mean 0.000003\n",
      "modality_trunks.vision.blocks.18.mlp.fc2.bias: grad mean 0.001779\n",
      "modality_trunks.vision.blocks.18.norm2.weight: grad mean 0.000657\n",
      "modality_trunks.vision.blocks.18.norm2.bias: grad mean 0.000805\n",
      "modality_trunks.vision.blocks.19.norm1.weight: grad mean 0.000744\n",
      "modality_trunks.vision.blocks.19.norm1.bias: grad mean 0.001018\n",
      "modality_trunks.vision.blocks.19.mlp.fc1.weight: grad mean 0.000003\n",
      "modality_trunks.vision.blocks.19.mlp.fc1.bias: grad mean 0.000799\n",
      "modality_trunks.vision.blocks.19.mlp.fc2.weight: grad mean 0.000003\n",
      "modality_trunks.vision.blocks.19.mlp.fc2.bias: grad mean 0.002220\n",
      "modality_trunks.vision.blocks.19.norm2.weight: grad mean 0.000807\n",
      "modality_trunks.vision.blocks.19.norm2.bias: grad mean 0.001015\n",
      "modality_trunks.vision.blocks.20.norm1.weight: grad mean 0.000961\n",
      "modality_trunks.vision.blocks.20.norm1.bias: grad mean 0.001262\n",
      "modality_trunks.vision.blocks.20.mlp.fc1.weight: grad mean 0.000004\n",
      "modality_trunks.vision.blocks.20.mlp.fc1.bias: grad mean 0.001108\n",
      "modality_trunks.vision.blocks.20.mlp.fc2.weight: grad mean 0.000005\n",
      "modality_trunks.vision.blocks.20.mlp.fc2.bias: grad mean 0.002995\n",
      "modality_trunks.vision.blocks.20.norm2.weight: grad mean 0.001088\n",
      "modality_trunks.vision.blocks.20.norm2.bias: grad mean 0.001344\n",
      "modality_trunks.vision.blocks.21.norm1.weight: grad mean 0.001383\n",
      "modality_trunks.vision.blocks.21.norm1.bias: grad mean 0.001819\n",
      "modality_trunks.vision.blocks.21.mlp.fc1.weight: grad mean 0.000006\n",
      "modality_trunks.vision.blocks.21.mlp.fc1.bias: grad mean 0.001538\n",
      "modality_trunks.vision.blocks.21.mlp.fc2.weight: grad mean 0.000007\n",
      "modality_trunks.vision.blocks.21.mlp.fc2.bias: grad mean 0.004190\n",
      "modality_trunks.vision.blocks.21.norm2.weight: grad mean 0.001516\n",
      "modality_trunks.vision.blocks.21.norm2.bias: grad mean 0.001914\n",
      "modality_trunks.vision.blocks.22.norm1.weight: grad mean 0.001710\n",
      "modality_trunks.vision.blocks.22.norm1.bias: grad mean 0.002258\n",
      "modality_trunks.vision.blocks.22.mlp.fc1.weight: grad mean 0.000008\n",
      "modality_trunks.vision.blocks.22.mlp.fc1.bias: grad mean 0.002128\n",
      "modality_trunks.vision.blocks.22.mlp.fc2.weight: grad mean 0.000009\n",
      "modality_trunks.vision.blocks.22.mlp.fc2.bias: grad mean 0.005777\n",
      "modality_trunks.vision.blocks.22.norm2.weight: grad mean 0.002029\n",
      "modality_trunks.vision.blocks.22.norm2.bias: grad mean 0.002633\n",
      "modality_trunks.vision.blocks.23.norm1.weight: grad mean 0.002365\n",
      "modality_trunks.vision.blocks.23.norm1.bias: grad mean 0.003175\n",
      "modality_trunks.vision.blocks.23.mlp.fc1.weight: grad mean 0.000012\n",
      "modality_trunks.vision.blocks.23.mlp.fc1.bias: grad mean 0.002965\n",
      "modality_trunks.vision.blocks.23.mlp.fc2.weight: grad mean 0.000012\n",
      "modality_trunks.vision.blocks.23.mlp.fc2.bias: grad mean 0.008197\n",
      "modality_trunks.vision.blocks.23.norm2.weight: grad mean 0.002855\n",
      "modality_trunks.vision.blocks.23.norm2.bias: grad mean 0.003672\n",
      "modality_trunks.text.blocks.0.attn.in_proj_weight: grad mean 0.000017\n",
      "modality_trunks.text.blocks.0.attn.in_proj_bias: grad mean 0.003257\n",
      "modality_trunks.text.blocks.0.attn.out_proj.weight: grad mean 0.000037\n",
      "modality_trunks.text.blocks.0.attn.out_proj.bias: grad mean 0.009978\n",
      "modality_trunks.text.blocks.0.norm1.weight: grad mean 0.000448\n",
      "modality_trunks.text.blocks.0.norm1.bias: grad mean 0.000561\n",
      "modality_trunks.text.blocks.0.mlp.fc1.weight: grad mean 0.000002\n",
      "modality_trunks.text.blocks.0.mlp.fc1.bias: grad mean 0.000455\n",
      "modality_trunks.text.blocks.0.mlp.fc2.weight: grad mean 0.000002\n",
      "modality_trunks.text.blocks.0.mlp.fc2.bias: grad mean 0.001256\n",
      "modality_trunks.text.blocks.0.norm2.weight: grad mean 0.000450\n",
      "modality_trunks.text.blocks.0.norm2.bias: grad mean 0.000568\n",
      "modality_trunks.text.blocks.1.norm1.weight: grad mean 0.000485\n",
      "modality_trunks.text.blocks.1.norm1.bias: grad mean 0.000644\n",
      "modality_trunks.text.blocks.1.mlp.fc1.weight: grad mean 0.000002\n",
      "modality_trunks.text.blocks.1.mlp.fc1.bias: grad mean 0.000476\n",
      "modality_trunks.text.blocks.1.mlp.fc2.weight: grad mean 0.000002\n",
      "modality_trunks.text.blocks.1.mlp.fc2.bias: grad mean 0.001317\n",
      "modality_trunks.text.blocks.1.norm2.weight: grad mean 0.000447\n",
      "modality_trunks.text.blocks.1.norm2.bias: grad mean 0.000589\n",
      "modality_trunks.text.blocks.2.norm1.weight: grad mean 0.000492\n",
      "modality_trunks.text.blocks.2.norm1.bias: grad mean 0.000655\n",
      "modality_trunks.text.blocks.2.mlp.fc1.weight: grad mean 0.000002\n",
      "modality_trunks.text.blocks.2.mlp.fc1.bias: grad mean 0.000504\n",
      "modality_trunks.text.blocks.2.mlp.fc2.weight: grad mean 0.000002\n",
      "modality_trunks.text.blocks.2.mlp.fc2.bias: grad mean 0.001367\n",
      "modality_trunks.text.blocks.2.norm2.weight: grad mean 0.000512\n",
      "modality_trunks.text.blocks.2.norm2.bias: grad mean 0.000639\n",
      "modality_trunks.text.blocks.3.norm1.weight: grad mean 0.000509\n",
      "modality_trunks.text.blocks.3.norm1.bias: grad mean 0.000701\n",
      "modality_trunks.text.blocks.3.mlp.fc1.weight: grad mean 0.000002\n",
      "modality_trunks.text.blocks.3.mlp.fc1.bias: grad mean 0.000587\n",
      "modality_trunks.text.blocks.3.mlp.fc2.weight: grad mean 0.000002\n",
      "modality_trunks.text.blocks.3.mlp.fc2.bias: grad mean 0.001606\n",
      "modality_trunks.text.blocks.3.norm2.weight: grad mean 0.000584\n",
      "modality_trunks.text.blocks.3.norm2.bias: grad mean 0.000745\n",
      "modality_trunks.text.blocks.4.norm1.weight: grad mean 0.000661\n",
      "modality_trunks.text.blocks.4.norm1.bias: grad mean 0.000865\n",
      "modality_trunks.text.blocks.4.mlp.fc1.weight: grad mean 0.000003\n",
      "modality_trunks.text.blocks.4.mlp.fc1.bias: grad mean 0.000674\n",
      "modality_trunks.text.blocks.4.mlp.fc2.weight: grad mean 0.000003\n",
      "modality_trunks.text.blocks.4.mlp.fc2.bias: grad mean 0.001811\n",
      "modality_trunks.text.blocks.4.norm2.weight: grad mean 0.000676\n",
      "modality_trunks.text.blocks.4.norm2.bias: grad mean 0.000846\n",
      "modality_trunks.text.blocks.5.norm1.weight: grad mean 0.000760\n",
      "modality_trunks.text.blocks.5.norm1.bias: grad mean 0.001029\n",
      "modality_trunks.text.blocks.5.mlp.fc1.weight: grad mean 0.000003\n",
      "modality_trunks.text.blocks.5.mlp.fc1.bias: grad mean 0.000855\n",
      "modality_trunks.text.blocks.5.mlp.fc2.weight: grad mean 0.000004\n",
      "modality_trunks.text.blocks.5.mlp.fc2.bias: grad mean 0.002389\n",
      "modality_trunks.text.blocks.5.norm2.weight: grad mean 0.000870\n",
      "modality_trunks.text.blocks.5.norm2.bias: grad mean 0.001097\n",
      "modality_trunks.text.blocks.6.norm1.weight: grad mean 0.000958\n",
      "modality_trunks.text.blocks.6.norm1.bias: grad mean 0.001345\n",
      "modality_trunks.text.blocks.6.mlp.fc1.weight: grad mean 0.000005\n",
      "modality_trunks.text.blocks.6.mlp.fc1.bias: grad mean 0.001153\n",
      "modality_trunks.text.blocks.6.mlp.fc2.weight: grad mean 0.000005\n",
      "modality_trunks.text.blocks.6.mlp.fc2.bias: grad mean 0.003078\n",
      "modality_trunks.text.blocks.6.norm2.weight: grad mean 0.001153\n",
      "modality_trunks.text.blocks.6.norm2.bias: grad mean 0.001453\n",
      "modality_trunks.text.blocks.7.norm1.weight: grad mean 0.001245\n",
      "modality_trunks.text.blocks.7.norm1.bias: grad mean 0.001658\n",
      "modality_trunks.text.blocks.7.mlp.fc1.weight: grad mean 0.000006\n",
      "modality_trunks.text.blocks.7.mlp.fc1.bias: grad mean 0.001435\n",
      "modality_trunks.text.blocks.7.mlp.fc2.weight: grad mean 0.000006\n",
      "modality_trunks.text.blocks.7.mlp.fc2.bias: grad mean 0.003826\n",
      "modality_trunks.text.blocks.7.norm2.weight: grad mean 0.001433\n",
      "modality_trunks.text.blocks.7.norm2.bias: grad mean 0.001775\n",
      "modality_trunks.text.blocks.8.norm1.weight: grad mean 0.001600\n",
      "modality_trunks.text.blocks.8.norm1.bias: grad mean 0.002127\n",
      "modality_trunks.text.blocks.8.mlp.fc1.weight: grad mean 0.000007\n",
      "modality_trunks.text.blocks.8.mlp.fc1.bias: grad mean 0.001806\n",
      "modality_trunks.text.blocks.8.mlp.fc2.weight: grad mean 0.000008\n",
      "modality_trunks.text.blocks.8.mlp.fc2.bias: grad mean 0.005099\n",
      "modality_trunks.text.blocks.8.norm2.weight: grad mean 0.001717\n",
      "modality_trunks.text.blocks.8.norm2.bias: grad mean 0.002197\n",
      "modality_trunks.text.blocks.9.norm1.weight: grad mean 0.002038\n",
      "modality_trunks.text.blocks.9.norm1.bias: grad mean 0.002726\n",
      "modality_trunks.text.blocks.9.mlp.fc1.weight: grad mean 0.000009\n",
      "modality_trunks.text.blocks.9.mlp.fc1.bias: grad mean 0.002149\n",
      "modality_trunks.text.blocks.9.mlp.fc2.weight: grad mean 0.000009\n",
      "modality_trunks.text.blocks.9.mlp.fc2.bias: grad mean 0.006143\n",
      "modality_trunks.text.blocks.9.norm2.weight: grad mean 0.002155\n",
      "modality_trunks.text.blocks.9.norm2.bias: grad mean 0.002738\n",
      "modality_trunks.text.blocks.10.norm1.weight: grad mean 0.002446\n",
      "modality_trunks.text.blocks.10.norm1.bias: grad mean 0.003311\n",
      "modality_trunks.text.blocks.10.mlp.fc1.weight: grad mean 0.000011\n",
      "modality_trunks.text.blocks.10.mlp.fc1.bias: grad mean 0.002672\n",
      "modality_trunks.text.blocks.10.mlp.fc2.weight: grad mean 0.000011\n",
      "modality_trunks.text.blocks.10.mlp.fc2.bias: grad mean 0.007557\n",
      "modality_trunks.text.blocks.10.norm2.weight: grad mean 0.002699\n",
      "modality_trunks.text.blocks.10.norm2.bias: grad mean 0.003434\n",
      "modality_trunks.text.blocks.11.norm1.weight: grad mean 0.003082\n",
      "modality_trunks.text.blocks.11.norm1.bias: grad mean 0.004223\n",
      "modality_trunks.text.blocks.11.mlp.fc1.weight: grad mean 0.000016\n",
      "modality_trunks.text.blocks.11.mlp.fc1.bias: grad mean 0.004060\n",
      "modality_trunks.text.blocks.11.mlp.fc2.weight: grad mean 0.000017\n",
      "modality_trunks.text.blocks.11.mlp.fc2.bias: grad mean 0.011538\n",
      "modality_trunks.text.blocks.11.norm2.weight: grad mean 0.003854\n",
      "modality_trunks.text.blocks.11.norm2.bias: grad mean 0.004810\n",
      "modality_heads.vision.0.weight: grad mean 0.003423\n",
      "modality_heads.vision.0.bias: grad mean 0.004810\n",
      "modality_heads.vision.2.weight: grad mean 0.000021\n",
      "modality_heads.text.proj.0.weight: grad mean 0.004428\n",
      "modality_heads.text.proj.0.bias: grad mean 0.005849\n",
      "modality_heads.text.proj.1.weight: grad mean 0.000024\n",
      "modality_postprocessors.text.1.log_logit_scale: grad mean 0.512418\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"{name}: grad mean {param.grad.abs().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "457d8ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ modality_preprocessors.vision.cls_tokens has grad with mean 0.00000\n",
      "✅ modality_preprocessors.vision.rgbt_stem.proj.1.weight has grad with mean -0.00000\n",
      "✅ modality_preprocessors.vision.pos_embed_helper.pos_embed has grad with mean -0.00000\n",
      "✅ modality_preprocessors.text.pos_embed has grad with mean 0.00000\n",
      "✅ modality_preprocessors.text.token_embedding.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.pre_transformer_layer.0.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.pre_transformer_layer.0.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.0.attn.in_proj_weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.0.attn.in_proj_bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.0.attn.out_proj.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.0.attn.out_proj.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.0.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.0.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.0.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.0.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.0.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.0.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.0.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.0.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.1.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.1.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.1.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.1.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.1.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.1.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.1.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.1.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.2.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.2.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.2.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.2.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.2.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.2.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.2.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.2.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.3.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.3.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.3.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.3.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.3.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.3.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.3.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.3.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.4.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.4.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.4.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.4.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.4.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.4.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.4.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.4.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.5.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.5.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.5.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.5.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.5.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.5.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.5.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.5.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.6.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.6.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.6.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.6.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.6.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.6.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.6.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.6.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.7.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.7.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.7.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.7.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.7.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.7.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.7.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.7.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.8.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.8.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.8.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.8.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.8.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.8.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.8.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.8.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.9.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.9.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.9.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.9.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.9.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.9.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.9.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.9.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.10.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.10.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.10.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.10.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.10.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.10.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.10.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.10.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.11.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.11.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.11.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.11.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.11.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.11.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.11.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.11.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.12.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.12.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.12.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.12.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.12.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.12.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.12.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.12.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.13.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.13.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.13.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.13.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.13.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.13.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.13.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.13.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.14.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.14.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.14.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.14.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.14.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.14.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.14.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.14.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.15.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.15.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.15.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.15.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.15.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.15.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.15.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.15.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.16.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.16.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.16.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.16.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.16.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.16.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.16.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.16.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.17.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.17.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.17.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.17.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.17.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.17.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.17.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.17.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.18.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.18.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.18.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.18.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.18.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.18.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.18.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.18.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.19.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.19.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.19.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.19.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.19.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.19.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.19.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.19.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.20.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.20.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.20.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.20.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.20.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.20.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.20.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.20.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.21.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.21.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.21.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.21.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.21.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.21.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.21.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.21.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.22.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.22.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.22.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.22.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.22.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.22.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.vision.blocks.22.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.22.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.23.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.23.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.23.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.23.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.23.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.23.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.vision.blocks.23.norm2.weight has grad with mean -0.00001\n",
      "✅ modality_trunks.vision.blocks.23.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.attn.in_proj_weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.attn.in_proj_bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.0.attn.out_proj.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.attn.out_proj.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.0.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.0.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.1.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.1.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.1.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.1.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.1.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.1.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.1.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.1.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.2.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.2.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.2.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.2.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.2.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.2.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.2.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.2.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.3.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.3.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.3.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.3.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.3.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.3.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.3.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.3.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.4.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.4.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.4.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.4.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.4.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.4.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.4.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.4.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.5.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.5.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.5.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.5.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.5.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.5.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.5.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.5.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.6.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.6.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.6.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.6.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.6.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.6.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.6.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.6.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.7.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.7.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.7.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.7.mlp.fc1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.7.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.7.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.7.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.7.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.8.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.8.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.8.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.8.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.8.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.8.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.8.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.8.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.9.norm1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.9.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.9.mlp.fc1.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.9.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.9.mlp.fc2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.9.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.9.norm2.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.9.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.10.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.10.norm1.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.10.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.10.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.10.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.10.mlp.fc2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.10.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.10.norm2.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.11.norm1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.11.norm1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.11.mlp.fc1.weight has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.11.mlp.fc1.bias has grad with mean 0.00000\n",
      "✅ modality_trunks.text.blocks.11.mlp.fc2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.11.mlp.fc2.bias has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.11.norm2.weight has grad with mean -0.00000\n",
      "✅ modality_trunks.text.blocks.11.norm2.bias has grad with mean -0.00000\n",
      "✅ modality_heads.vision.0.weight has grad with mean -0.00006\n",
      "✅ modality_heads.vision.0.bias has grad with mean 0.00002\n",
      "✅ modality_heads.vision.2.weight has grad with mean 0.00000\n",
      "✅ modality_heads.text.proj.0.weight has grad with mean -0.00008\n",
      "✅ modality_heads.text.proj.0.bias has grad with mean 0.00000\n",
      "✅ modality_heads.text.proj.1.weight has grad with mean 0.00000\n",
      "✅ modality_postprocessors.text.1.log_logit_scale has grad with mean 0.51065\n"
     ]
    }
   ],
   "source": [
    "output = model(inputs)\n",
    "loss = loss_fn(output['vision'], output['text'])\n",
    "loss.backward()\n",
    "\n",
    "# Check gradients\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"✅ {name} has grad with mean {param.grad.mean().item():.5f}\")\n",
    "    else:\n",
    "        print(f\"❌ {name} has NO grad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f53fdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b244d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Images shape: torch.Size([3, 3, 224, 224])\n",
      "Loaded Texts shape: torch.Size([3, 77])\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import load_and_transform_vision_data, load_and_transform_text\n",
    "\n",
    "text_list = [\"close up of a brown and white pet dog\", \"little kitten playing his toy mouse\", \"video of funny cat\"]\n",
    "\n",
    "images = load_and_transform_vision_data(image_paths = \"Test Data/Image_Data\", device = \"cpu\")\n",
    "texts = load_and_transform_text(texts = text_list, device = \"cpu\")\n",
    "\n",
    "print(f\"Loaded Images shape: {images.shape}\")\n",
    "print(f\"Loaded Texts shape: {texts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0a643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07bc4039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3306, 1.3307, 1.3306],\n",
       "        [1.3313, 1.3314, 1.3313],\n",
       "        [1.3306, 1.3306, 1.3306]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f31c6430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.3333, 0.3333],\n",
       "        [0.3333, 0.3333, 0.3333],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_x_text = torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T, dim=-1)\n",
    "vision_x_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
