{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eba29a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "import math\n",
    "from timm.models.layers import trunc_normal_\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4ce0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyLayer(\n",
      "  (running_mean): tensor((5,), requires_grad=False)\n",
      "  \n",
      "  (linear): Linear(in_features=1, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VerboseNNModule(nn.Module):\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_readable_tensor_representation(name: str, tensor: torch.Tensor):\n",
    "        st = (\n",
    "            \"(\" + name + \"): \" + \"tensor(\" + str(tuple(tensor[1].shape)) + \", requires_grad=\" + str(tensor[1].requires_grad) + \")\\n\"\n",
    "            )\n",
    "        return st\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        named_modules = set()\n",
    "        for p in self.named_modules():\n",
    "            named_modules.update(p[0])\n",
    "        named_modules = list(named_modules)\n",
    "\n",
    "        string_repr = \"\"\n",
    "        for p in self.named_parameters():\n",
    "            name = p[0].split(\".\")[0]\n",
    "            if name in named_modules:\n",
    "                string_repr += self.get_readable_tensor_representation(name, p)\n",
    "        \n",
    "        for p in self.named_buffers():\n",
    "            name = p[0].split(\".\")[0]\n",
    "            string_repr += self.get_readable_tensor_representation(name, p)\n",
    "        \n",
    "        return string_repr\n",
    "\n",
    "class MyLayer(VerboseNNModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 2)\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(5))\n",
    "\n",
    "# Instantiate and print the model\n",
    "model = MyLayer()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8aef52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_causal_attention_mask(context_length):\n",
    "    mask = torch.empty(context_length, context_length, requires_grad=False)\n",
    "    mask.fill_(float(\"-inf\"))\n",
    "    mask.triu_(1)\n",
    "    return mask\n",
    "\n",
    "build_causal_attention_mask(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a94d826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 77, 768])\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessor(VerboseNNModule):\n",
    "    def __init__(self, vocab_size: int, context_length: int, embed_dim: int, causual_mask: bool, \n",
    "                 supply_seq_len_to_head: bool = True, init_param_style: str = \"openclip\"):\n",
    "        \"\"\"\n",
    "        `vocab_size`: Number of tokens in your vocabulary.                 the number of words in your text, so we can map nn.Embedding\n",
    "\t    `context_length`: Maximum number of tokens per input sequence.     usually: 77\n",
    "\t    `embed_dim`: Dimensionality of each token embedding.               usually: 768\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.context_length = context_length\n",
    "        self.causual_mask = causual_mask\n",
    "        self.embed_dim = embed_dim\n",
    "        self.supply_seq_len_to_head = supply_seq_len_to_head\n",
    "        \n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_embed = nn.Parameter(\n",
    "            torch.empty(1, context_length, embed_dim)\n",
    "        )\n",
    "        if causual_mask:\n",
    "            mask = build_causal_attention_mask(context_length)\n",
    "            self.register_buffer(\"mask\", mask) # register the mask as a buffer so it can be moved to the right device\n",
    "        \n",
    "        self.init_parameters(init_param_style)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_parameters(self, init_param_style = \"openclip\"):\n",
    "        nn.init.normal_(self.token_embedding.weight, std=0.02)\n",
    "        nn.init.normal_(self.pos_embed, std=0.02)\n",
    "\n",
    "        # I did'nt use init_param_style as I was too lazy to implment [CLS]\n",
    "    \n",
    "    def forward(self, text):\n",
    "        token_text = self.token_embedding(text)\n",
    "        token_text = token_text + self.pos_embed\n",
    "        \n",
    "        return_dict = {\n",
    "            \"trunk\": {\n",
    "                \"tokens\": token_text\n",
    "            },\n",
    "            \"head\": {},\n",
    "        }\n",
    "\n",
    "        if self.supply_seq_len_to_head:\n",
    "            text_lengths = text.argmax(dim = -1)\n",
    "            #  hacky and non-standard way of getting the sequence length.\n",
    "            return_dict[\"head\"] = {\n",
    "                \"seq_len\": text_lengths,\n",
    "            }\n",
    "        if self.causual_mask:\n",
    "            return_dict[\"trunk\"].update({\"attn_mask\": self.mask})\n",
    "        \n",
    "        return return_dict\n",
    "    \n",
    "vocab_size = 100\n",
    "context_length = 77\n",
    "embed_dim = 768\n",
    "\n",
    "# Sample input: batch of 1, padded or truncated to 77 tokens\n",
    "text = torch.randint(0, vocab_size, (2, context_length))  # shape [1, 77]\n",
    "\n",
    "text_processor = TextPreprocessor(\n",
    "    vocab_size=vocab_size,\n",
    "    context_length=context_length,\n",
    "    embed_dim=embed_dim,\n",
    "    causual_mask=True,\n",
    "    supply_seq_len_to_head=True\n",
    ")\n",
    "\n",
    "out = text_processor(text)\n",
    "print(out[\"trunk\"][\"tokens\"].shape)  # âžœ [2, 77, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1d3395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([77, 77])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"trunk\"][\"attn_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935c1cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"head\"][\"seq_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5912916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextPreprocessor(\n",
      "  (mask): tensor((77, 77), requires_grad=False)\n",
      "  \n",
      "  (token_embedding): Embedding(100, 768)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(text_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9716d23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32768, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PatchEmbedGeneric(nn.Module):\n",
    "    def __init__(self, proj_stem, norm_layer: Optional[Callable] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if len(proj_stem) > 1:\n",
    "            self.proj_stem = nn.Sequential(*proj_stem)\n",
    "        else:\n",
    "            # Special case to be able to load pre-trained models that were\n",
    "            # trained with a standard stem\n",
    "            self.proj = proj_stem[0]\n",
    "        self.norm_layer = norm_layer\n",
    "    \n",
    "    def get_patch_layout(self, image_size):\n",
    "        with torch.no_grad():\n",
    "            dummy_img = torch.zeros([1,]) + image_size   # 1, C, (T), H, W\n",
    "            dummy_out = self.proj(dummy_img)\n",
    "        \n",
    "        embed_dim = dummy_out[1]                        # `embed_dim`    = C        \n",
    "        patch_layout = tuple(dummy_out.shape[2:])             # `patch_layout` = (T), H, W       \n",
    "        num_patches = np.prod(patch_layout)             # `num_patches`  = (T) * H * W       \n",
    "        return embed_dim, patch_layout, num_patches\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.flatten(2)                                # B, C, (T), H, W -> B, C, (T)*H*W\n",
    "        x = x.transpose(1, 2)                           # B, C, (T)*H*W   -> B, (T)*H*W, C\n",
    "        if self.norm_layer is not None:\n",
    "            x = self.norm_layer(x)\n",
    "        return x\n",
    "\n",
    "## Testing\n",
    "proj_stem = [\n",
    "    nn.Conv3d(3, 16, kernel_size=3, stride=2, padding=1),  # Assume input is (B, 3, 8, 64, 64)\n",
    "    nn.ReLU()\n",
    "]\n",
    "\n",
    "patch_embed = PatchEmbedGeneric(proj_stem)\n",
    "x = torch.randn(2, 3, 8, 64, 64)\n",
    "\n",
    "out = patch_embed(x)\n",
    "out.shape\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb127a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1390ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
